{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Linux下添加此代码,添加临时模块搜索路径(pycharm下当前项目为搜索路径)\n",
    "sys.path.append(os.path.abspath(\"..\" + os.sep + \"..\" + os.sep + \"..\"))\n",
    "\n",
    "from tianchi_NewsTextClassification.core.models.textrnn_model import TextRNN\n",
    "from tianchi_NewsTextClassification.core.utils.train_evaluate import Trainer\n",
    "\n",
    "%run ../models/textrnn_model.py\n",
    "%run ../utils/train_evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = joblib.load('../../intermediate_save_data/X_train.pkl')\n",
    "y_train = joblib.load('../../intermediate_save_data/y_train.pkl')\n",
    "X_test = joblib.load('../../intermediate_save_data/X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.8134e+00, -4.1394e+00,  1.1417e+00,  ...,  3.5465e+00,\n",
       "          2.9921e-02, -8.0849e-01],\n",
       "        ...,\n",
       "        [ 2.7235e-03,  7.6506e-03, -7.8161e-02,  ..., -7.4759e-03,\n",
       "         -1.0344e-01, -1.2040e-01],\n",
       "        [ 8.8274e-02,  9.2499e-02, -3.2991e-02,  ..., -1.7648e-02,\n",
       "         -1.1850e-01, -2.1958e-02],\n",
       "        [-1.1811e-01,  3.4976e-02,  1.8313e-02,  ..., -7.8549e-02,\n",
       "         -1.6537e-01, -1.1834e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载词典\n",
    "load_vocal = joblib.load('../../intermediate_save_data/vocal.pkl')\n",
    "\n",
    "# 加载预训练词向量文件\n",
    "vector = torchtext.vocab.Vectors(name=\"cnew_200.txt\",\n",
    "                                 cache='../../intermediate_save_data')\n",
    "\n",
    "pretrained_vector = vector.get_vecs_by_tokens(load_vocal.get_itos())\n",
    "pretrained_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocal_size, embedding_size = pretrained_vector.shape\n",
    "hidden_size = 256\n",
    "dropout = 0.5\n",
    "bidirectional = True\n",
    "out_size = 14\n",
    "num_layers = 2\n",
    "\n",
    "net = TextRNN(vocab_size=vocal_size,\n",
    "              embedding_size=embedding_size,\n",
    "              hidden_size=hidden_size,\n",
    "              num_layers=num_layers,\n",
    "              dropout_ratio=dropout,\n",
    "              bidirectional=True,\n",
    "              out_size=out_size)\n",
    "net.embed.weight.data.copy_(pretrained_vector)  # 使用预训练词向量矩阵\n",
    "net = net.to(device)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "params_1x = [param for name, param in net.named_parameters() if name not in [\"embed.weight\"]]\n",
    "optimer = torch.optim.Adam([{'params': params_1x, 'lr': lr}, \n",
    "                            {'params': net.embed.parameters(), 'lr': 0.00025}])  # 预训练词向量使用更低的学习率\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def compute_metrics_acc(predict_all, y_true):\n",
    "    predict = predict_all.argmax(-1)\n",
    "    label = y_true\n",
    "    acc = accuracy_score(label, predict)\n",
    "    return {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "def collate_fun(data):\n",
    "    text, label = default_collate(data)\n",
    "    text = text.transpose(0, 1)\n",
    "    return text, label\n",
    "\n",
    "\n",
    "dataset_tr = Data.TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "dataloader_tr = Data.DataLoader(dataset_tr, 64, shuffle=True, collate_fn=collate_fun)\n",
    "\n",
    "for i, j in dataloader_tr:\n",
    "    print(i.shape)\n",
    "    print(j.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_and_v = Trainer(model=net, optimizer=optimer, criterion=loss, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0  [0    /200000 (0  %)]\tLoss: 2.633695\tacc: 0.093750\n",
      "Train Epoch: 0  [32000/200000 (16 %)]\tLoss: 0.297576\tacc: 0.921875\n",
      "Train Epoch: 0  [64000/200000 (32 %)]\tLoss: 0.521308\tacc: 0.890625\n",
      "Train Epoch: 0  [96000/200000 (48 %)]\tLoss: 0.361424\tacc: 0.875000\n",
      "Train Epoch: 0  [128000/200000 (64 %)]\tLoss: 0.345332\tacc: 0.890625\n",
      "Train Epoch: 0  [160000/200000 (80 %)]\tLoss: 0.312838\tacc: 0.906250\n",
      "Train Epoch: 0  [192000/200000 (96 %)]\tLoss: 0.349455\tacc: 0.890625\n",
      "Train Epoch: 0  [200000/200000 (100%)]\tLoss: 0.092576\tacc: 0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 1  [0    /200000 (0  %)]\tLoss: 0.328936\tacc: 0.890625\n",
      "Train Epoch: 1  [32000/200000 (16 %)]\tLoss: 0.135691\tacc: 0.953125\n",
      "Train Epoch: 1  [64000/200000 (32 %)]\tLoss: 0.209174\tacc: 0.921875\n",
      "Train Epoch: 1  [96000/200000 (48 %)]\tLoss: 0.071882\tacc: 0.984375\n",
      "Train Epoch: 1  [128000/200000 (64 %)]\tLoss: 0.245944\tacc: 0.921875\n",
      "Train Epoch: 1  [160000/200000 (80 %)]\tLoss: 0.074064\tacc: 0.984375\n",
      "Train Epoch: 1  [192000/200000 (96 %)]\tLoss: 0.344243\tacc: 0.890625\n",
      "Train Epoch: 1  [200000/200000 (100%)]\tLoss: 0.543140\tacc: 0.875000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 2  [0    /200000 (0  %)]\tLoss: 0.286361\tacc: 0.906250\n",
      "Train Epoch: 2  [32000/200000 (16 %)]\tLoss: 0.362519\tacc: 0.906250\n",
      "Train Epoch: 2  [64000/200000 (32 %)]\tLoss: 0.369849\tacc: 0.906250\n",
      "Train Epoch: 2  [96000/200000 (48 %)]\tLoss: 0.354167\tacc: 0.921875\n",
      "Train Epoch: 2  [128000/200000 (64 %)]\tLoss: 0.429089\tacc: 0.921875\n",
      "Train Epoch: 2  [160000/200000 (80 %)]\tLoss: 0.300478\tacc: 0.890625\n",
      "Train Epoch: 2  [192000/200000 (96 %)]\tLoss: 0.239455\tacc: 0.921875\n",
      "Train Epoch: 2  [200000/200000 (100%)]\tLoss: 0.230707\tacc: 0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 3  [0    /200000 (0  %)]\tLoss: 0.084826\tacc: 0.968750\n",
      "Train Epoch: 3  [32000/200000 (16 %)]\tLoss: 0.162007\tacc: 0.937500\n",
      "Train Epoch: 3  [64000/200000 (32 %)]\tLoss: 0.177265\tacc: 0.968750\n",
      "Train Epoch: 3  [96000/200000 (48 %)]\tLoss: 0.167994\tacc: 0.968750\n",
      "Train Epoch: 3  [128000/200000 (64 %)]\tLoss: 0.282447\tacc: 0.906250\n",
      "Train Epoch: 3  [160000/200000 (80 %)]\tLoss: 0.122671\tacc: 0.968750\n",
      "Train Epoch: 3  [192000/200000 (96 %)]\tLoss: 0.220611\tacc: 0.937500\n",
      "Train Epoch: 3  [200000/200000 (100%)]\tLoss: 0.152533\tacc: 0.984375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 4  [0    /200000 (0  %)]\tLoss: 0.279771\tacc: 0.875000\n",
      "Train Epoch: 4  [32000/200000 (16 %)]\tLoss: 0.145103\tacc: 0.953125\n",
      "Train Epoch: 4  [64000/200000 (32 %)]\tLoss: 0.169142\tacc: 0.937500\n",
      "Train Epoch: 4  [96000/200000 (48 %)]\tLoss: 0.139158\tacc: 0.968750\n",
      "Train Epoch: 4  [128000/200000 (64 %)]\tLoss: 0.098086\tacc: 0.953125\n",
      "Train Epoch: 4  [160000/200000 (80 %)]\tLoss: 0.191606\tacc: 0.921875\n",
      "Train Epoch: 4  [192000/200000 (96 %)]\tLoss: 0.208814\tacc: 0.937500\n",
      "Train Epoch: 4  [200000/200000 (100%)]\tLoss: 0.146197\tacc: 0.968750\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_and_v.train(dataloader_tr,  compute_metrics=compute_metrics_acc, verbose=500, estimate_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fun_test(data):\n",
    "    text = default_collate(data)[0]\n",
    "    text = text.transpose(0, 1)\n",
    "    return text, \n",
    "\n",
    "\n",
    "dataset_te = Data.TensorDataset(torch.tensor(X_test))\n",
    "dataloader_te = Data.DataLoader(dataset_te, 64, collate_fn=collate_fun_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0696,  9.6873, -4.6693,  ..., -8.7026, -4.8898, -9.0701],\n",
       "        [-0.0979, -1.9580, 12.9226,  ..., -4.6836,  2.2152, -8.3977],\n",
       "        [ 0.9576, -0.2485, -3.2080,  ...,  0.3543, -6.8835, -4.0182],\n",
       "        ...,\n",
       "        [-1.1301,  6.6643, -3.7873,  ..., -4.8817, -4.4219, -6.7376],\n",
       "        [-0.2524, -1.9369,  0.0388,  ..., -0.4760, -4.9485, -4.7881],\n",
       "        [-0.0329,  7.9241, -4.4056,  ..., -5.5392, -3.9979, -6.1183]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pro = t_and_v.predict(dataloader_te, status='Test')\n",
    "result_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          1\n",
       "1          2\n",
       "2          8\n",
       "3          5\n",
       "4          0\n",
       "...      ...\n",
       "49995      0\n",
       "49996     13\n",
       "49997      1\n",
       "49998      3\n",
       "49999      1\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_result_label = np.argmax(result_pro.cpu().numpy(), axis=1)\n",
    "pre_result_label = pd.DataFrame(pre_result_label, columns=['label'])\n",
    "pre_result_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不使用预训练词向量权重=>线上F1 score:0.9360\n",
    "# 使用预训练词向量权重+梯度裁剪(梯度爆炸)=>线上F1 score:0.9484\n",
    "# 使用预训练词向量权重(学习率0.0001)+梯度裁剪(梯度爆炸)=>线上F1 score:0.9405\n",
    "# 使用预训练词向量权重(学习率0.00025)+梯度裁剪(梯度爆炸)=>线上F1 score:0.9414\n",
    "pre_result_label.to_csv('../../output/test_predictions_textrnn_w2v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
