{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Linux下添加此代码,添加临时模块搜索路径(pycharm下当前项目为搜索路径)\n",
    "sys.path.append(os.path.abspath(\"..\" + os.sep + \"..\" + os.sep + \"..\"))\n",
    "\n",
    "from tianchi_NewsTextClassification.core.models.textcnn_model import TextCNN\n",
    "from tianchi_NewsTextClassification.core.utils.train_evaluate import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = joblib.load('../../intermediate_save_data/X_train.pkl')\n",
    "y_train = joblib.load('../../intermediate_save_data/y_train.pkl')\n",
    "X_test = joblib.load('../../intermediate_save_data/X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.8134e+00, -4.1394e+00,  1.1417e+00,  ...,  3.5465e+00,\n",
       "          2.9921e-02, -8.0849e-01],\n",
       "        ...,\n",
       "        [ 2.7235e-03,  7.6506e-03, -7.8161e-02,  ..., -7.4759e-03,\n",
       "         -1.0344e-01, -1.2040e-01],\n",
       "        [ 8.8274e-02,  9.2499e-02, -3.2991e-02,  ..., -1.7648e-02,\n",
       "         -1.1850e-01, -2.1958e-02],\n",
       "        [-1.1811e-01,  3.4976e-02,  1.8313e-02,  ..., -7.8549e-02,\n",
       "         -1.6537e-01, -1.1834e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载词典\n",
    "load_vocal = joblib.load('../../intermediate_save_data/vocal.pkl')\n",
    "\n",
    "# 加载预训练词向量文件\n",
    "vector = torchtext.vocab.Vectors(name=\"cnew_200.txt\",\n",
    "                                 cache='../../intermediate_save_data')\n",
    "\n",
    "pretrained_vector = vector.get_vecs_by_tokens(load_vocal.get_itos())\n",
    "pretrained_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=666)\n",
    "\n",
    "kernel_sizes, nums_channels = [3, 4, 5, 10], [256, 256, 256]  # 卷积核大小和输出通道\n",
    "net = TextCNN(pretrained_vector.shape[0], pretrained_vector.shape[1], kernel_sizes, nums_channels)\n",
    "net.embedding.weight.data.copy_(pretrained_vector)\n",
    "net.constant_embedding.weight.data.copy_(pretrained_vector)  # 使用预训练词向量矩阵\n",
    "net.constant_embedding.weight.requires_grad = False  # 冻结网络层,使之不参与训练\n",
    "net = net.to(device)\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def compute_metrics_acc(predict_all, y_true):\n",
    "    predict = predict_all.argmax(-1)\n",
    "    label = y_true\n",
    "    acc = accuracy_score(label, predict)\n",
    "    return {\"acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_tr = Data.TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "dataloader_tr = Data.DataLoader(dataset_tr, 64, shuffle=True)\n",
    "\n",
    "t_and_v = Trainer(model=net, optimizer=optimer, criterion=loss, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0  [0    /200000 (0  %)]\tLoss: 9.504072\tacc: 0.015625\n",
      "Train Epoch: 0  [32000/200000 (16 %)]\tLoss: 1.060653\tacc: 0.734375\n",
      "Train Epoch: 0  [64000/200000 (32 %)]\tLoss: 0.678004\tacc: 0.843750\n",
      "Train Epoch: 0  [96000/200000 (48 %)]\tLoss: 0.852403\tacc: 0.781250\n",
      "Train Epoch: 0  [128000/200000 (64 %)]\tLoss: 0.722783\tacc: 0.812500\n",
      "Train Epoch: 0  [160000/200000 (80 %)]\tLoss: 1.002357\tacc: 0.750000\n",
      "Train Epoch: 0  [192000/200000 (96 %)]\tLoss: 0.655685\tacc: 0.859375\n",
      "Train Epoch: 0  [200000/200000 (100%)]\tLoss: 0.714647\tacc: 0.796875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 1  [0    /200000 (0  %)]\tLoss: 0.839801\tacc: 0.750000\n",
      "Train Epoch: 1  [32000/200000 (16 %)]\tLoss: 0.663092\tacc: 0.843750\n",
      "Train Epoch: 1  [64000/200000 (32 %)]\tLoss: 0.218422\tacc: 0.937500\n",
      "Train Epoch: 1  [96000/200000 (48 %)]\tLoss: 0.583931\tacc: 0.828125\n",
      "Train Epoch: 1  [128000/200000 (64 %)]\tLoss: 0.237658\tacc: 0.875000\n",
      "Train Epoch: 1  [160000/200000 (80 %)]\tLoss: 0.354797\tacc: 0.875000\n",
      "Train Epoch: 1  [192000/200000 (96 %)]\tLoss: 0.392038\tacc: 0.921875\n",
      "Train Epoch: 1  [200000/200000 (100%)]\tLoss: 0.570224\tacc: 0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 2  [0    /200000 (0  %)]\tLoss: 0.414923\tacc: 0.859375\n",
      "Train Epoch: 2  [32000/200000 (16 %)]\tLoss: 0.357252\tacc: 0.906250\n",
      "Train Epoch: 2  [64000/200000 (32 %)]\tLoss: 0.312974\tacc: 0.859375\n",
      "Train Epoch: 2  [96000/200000 (48 %)]\tLoss: 0.170442\tacc: 0.921875\n",
      "Train Epoch: 2  [128000/200000 (64 %)]\tLoss: 0.461607\tacc: 0.890625\n",
      "Train Epoch: 2  [160000/200000 (80 %)]\tLoss: 0.169921\tacc: 0.953125\n",
      "Train Epoch: 2  [192000/200000 (96 %)]\tLoss: 0.290916\tacc: 0.875000\n",
      "Train Epoch: 2  [200000/200000 (100%)]\tLoss: 0.348084\tacc: 0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 3  [0    /200000 (0  %)]\tLoss: 0.229491\tacc: 0.937500\n",
      "Train Epoch: 3  [32000/200000 (16 %)]\tLoss: 0.376848\tacc: 0.875000\n",
      "Train Epoch: 3  [64000/200000 (32 %)]\tLoss: 0.284274\tacc: 0.859375\n",
      "Train Epoch: 3  [96000/200000 (48 %)]\tLoss: 0.377591\tacc: 0.921875\n",
      "Train Epoch: 3  [128000/200000 (64 %)]\tLoss: 0.504931\tacc: 0.906250\n",
      "Train Epoch: 3  [160000/200000 (80 %)]\tLoss: 0.394540\tacc: 0.906250\n",
      "Train Epoch: 3  [192000/200000 (96 %)]\tLoss: 0.342469\tacc: 0.921875\n",
      "Train Epoch: 3  [200000/200000 (100%)]\tLoss: 0.457209\tacc: 0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Train Epoch: 4  [0    /200000 (0  %)]\tLoss: 0.188780\tacc: 0.921875\n",
      "Train Epoch: 4  [32000/200000 (16 %)]\tLoss: 0.577643\tacc: 0.796875\n",
      "Train Epoch: 4  [64000/200000 (32 %)]\tLoss: 0.505642\tacc: 0.906250\n",
      "Train Epoch: 4  [96000/200000 (48 %)]\tLoss: 0.401316\tacc: 0.921875\n",
      "Train Epoch: 4  [128000/200000 (64 %)]\tLoss: 0.189461\tacc: 0.968750\n",
      "Train Epoch: 4  [160000/200000 (80 %)]\tLoss: 0.288057\tacc: 0.937500\n",
      "Train Epoch: 4  [192000/200000 (96 %)]\tLoss: 0.351720\tacc: 0.906250\n",
      "Train Epoch: 4  [200000/200000 (100%)]\tLoss: 0.701086\tacc: 0.875000\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Training loss': [0.2938196063041687,\n",
       "  0.2223615199327469,\n",
       "  0.21034269034862518,\n",
       "  0.21819621324539185,\n",
       "  0.2022916078567505],\n",
       " 'Training acc': [0.91013, 0.93507, 0.940945, 0.93893, 0.94363]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_and_v.train(dataloader_tr,  compute_metrics=compute_metrics_acc, verbose=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.9219,  21.3851,  -5.3220,  ..., -14.6076,  -7.1964, -14.0717],\n",
       "        [ -1.5998,  -3.4869,  25.5887,  ...,  -9.3767,  13.2178, -22.2694],\n",
       "        [ -0.3742,  -3.3720, -12.6544,  ...,  -6.2024,  -9.8064, -16.5784],\n",
       "        ...,\n",
       "        [  1.3224,  11.1919,  -2.3225,  ..., -10.7451,  -8.2783, -10.2868],\n",
       "        [  3.9415,  -1.9201,   3.8571,  ...,   0.6587,  -6.3960, -12.3854],\n",
       "        [  2.6442,  11.3428,  -2.7230,  ...,  -3.2815,  -1.0528,  -6.9574]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_te = Data.TensorDataset(torch.tensor(X_test))\n",
    "dataloader_te = Data.DataLoader(dataset_te, 64)  # 测试数据集\n",
    "\n",
    "result_pro = t_and_v.predict(dataloader_te, status='Test')\n",
    "result_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          1\n",
       "1          2\n",
       "2          8\n",
       "3          5\n",
       "4          0\n",
       "...      ...\n",
       "49995      0\n",
       "49996     13\n",
       "49997      1\n",
       "49998      3\n",
       "49999      1\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_result_label = np.argmax(result_pro.cpu().numpy(), axis=1)\n",
    "pre_result_label = pd.DataFrame(pre_result_label, columns=['label'])\n",
    "pre_result_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_result_label.to_csv('../../output/test_predictions_textcnn_w2v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}